{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25b7e374",
   "metadata": {},
   "source": [
    "# Regression Models for Fa Prediction using Descriptors Calculated with Mordred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7282d3",
   "metadata": {},
   "source": [
    "## Materials and Method\n",
    "\n",
    "- Libraries: NumPy, pandas, scikit-learn, matplotlib, RDKit, mordred and SHAP\n",
    "- Dataset: Fraction of absorption (Fa) and Parmeability measured by Caco-2 cells (Papp), which were collected previous strudy (Esaki, et al., Journal of Phermeceutical Sciences, 2019)\n",
    "- Descriptor calcularion: Mordred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155cc289",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556e3a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "print('numpy version: ', np.__version__)\n",
    "print('pandas version: ', pd.__version__)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "print('scikit-learn version: ', sklearn.__version__)\n",
    "\n",
    "import shap\n",
    "print('shap version: ', shap.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304cec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Fa'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808b52a9",
   "metadata": {},
   "source": [
    "### Dataset Import\n",
    "\n",
    "The dataset contained information on the chemical structure of 5567 compounds as SMILES strings. In this dataset, the number of Fa experimental values was 946, respectively. Owing to its accuracy, we used CORINA (ver. 4.4.0) to generate 3D structures of the chemical compounds as structure data format (SDF) .\n",
    "\n",
    "We used the molecular descriptor calculator, Mordred, to calculate descriptors (1613 for 1D and 2D). These descriptors were calculated for Fa dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beed4568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_2Ddescriptors = pd.read_csv('CBIJ_Esaki_et_al_Descriptor_Mordred_1D2D.csv', index_col=0)\n",
    "df_2Ddescriptors.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28434a64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_2Ddescriptors = df_2Ddescriptors.drop(\"Papp\", axis=1)\n",
    "df_2Ddescriptors.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a0a993",
   "metadata": {},
   "source": [
    "## Definition of Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f019174",
   "metadata": {},
   "source": [
    "### Data preparation and Distribution conformation\n",
    "\n",
    "The Fa dataset was randomly split into training (70%, 660 compounds) and test set (30%, 286 compounds) using the train_test_split function in scikit-learn. The Fa measurements ranged between 0.0 and 1.0, with localization around either 0.0 or 1.0. We transformed these values to log10(Fa/(1 - Fa)) to scatter the response variable. Additionally, Fa = 0.0 was set to 0.01, and Fa = 1.0 was set to 0.99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07733507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_separation(df, target):\n",
    "    df = df.dropna(subset=[target])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 2:], df[target],\n",
    "                                                        train_size=0.7, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def distribution_conformation(df, target):\n",
    "    X_train, X_test, y_train, y_test = data_separation(df, target)\n",
    "    \n",
    "    # remove descriptors with nan\n",
    "    X_train = X_train.dropna(axis=1)\n",
    "    X_test = X_test[X_train.columns]\n",
    "    print(X_train.shape, X_test.shape, X_test.dropna(axis=1).shape)\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 3))\n",
    "    \n",
    "    for f in range(4):\n",
    "        ax = fig.add_subplot(1, 4, f+1)\n",
    "        if f == 0:\n",
    "            ax.hist(y_train, bins=25, label='Training set')\n",
    "            ax.hist(y_test, bins=25, label='Test set')\n",
    "            ax.set_title('{}'.format(target))\n",
    "        elif f == 1:\n",
    "            if target == 'Fa':\n",
    "                y_train[y_train == 0] = 0.01\n",
    "                y_train[y_train == 1] = 0.99\n",
    "                y_train = np.log(y_train/(1-y_train))\n",
    "                y_test[y_test == 0] = 0.01\n",
    "                y_test[y_test == 1] = 0.99\n",
    "                y_test = np.log(y_test/(1-y_test))\n",
    "            elif target == 'Papp':\n",
    "                y_train = np.log(y_train)\n",
    "                y_test = np.log(y_test)\n",
    "            ax.hist(y_train, bins=25, label='Training set')\n",
    "            ax.hist(y_test, bins=25, label='Test set')\n",
    "            ax.set_title('Converted {}'.format(target))\n",
    "        elif f == 2:\n",
    "            ax.hist(X_train['MW'], range=(0,700), bins=25, label='Training set')\n",
    "            ax.hist(X_test['MW'], range=(0,700), bins=25, label='Test set')\n",
    "            ax.set_title('MW: {} data'.format(target))\n",
    "        elif f == 3:\n",
    "            ax.hist(X_train['SLogP'], range=(-10,10), bins=25, label='Training set')\n",
    "            ax.hist(X_test['SLogP'], range=(-10,10), bins=25, label='Test set')\n",
    "            ax.set_title('SLogP: {} data'.format(target))\n",
    "        plt.legend(fontsize=12)\n",
    "    plt.show()\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa65c4c",
   "metadata": {},
   "source": [
    "### Descriptor preparation\n",
    "\n",
    "We performed data preparation steps for descriptors of compounds in the training set. First, descriptors with nan were removed. Next, descriptors with small variance were removed using the VarianceThreshold function (threshold=1.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020fe253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptor_preparation(X_train, X_test):\n",
    "    # Remove no variance descriptors\n",
    "    var = VarianceThreshold(threshold=1.0).fit(X_train)\n",
    "    X_train = X_train.loc[:, var.get_support()]\n",
    "    X_test = X_test.loc[:, var.get_support()]\n",
    "    \n",
    "    # Fill in NaNs with avereges\n",
    "    train_averages = X_train.mean()\n",
    "    X_test = X_test.fillna(train_averages)\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3767f037",
   "metadata": {},
   "source": [
    "### Model Construction\n",
    "\n",
    "To construct Random Forest Regression (RFR) model for Fa prediction. RFR is an ensemble model based on the decision tree method that requires us to optimize the following parameters: n_estimators: the number of trees, max_depth: the maximum depth, min_samples_split: minimum number of samples required to split an internal node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709a928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def model_construction_rfr(X_train, y_train):    \n",
    "    # RFR\n",
    "    search_params = [{\"max_depth\": [15, 17, 20, 25, 30],\n",
    "                      \"n_estimators\":[750, 1000, 1200, 1500, 1750, 2000],\n",
    "                      \"min_samples_split\": [2, 3, 5]}]\n",
    "    gs_rfr = GridSearchCV(RandomForestRegressor(random_state=0, n_jobs=-1),\n",
    "                          search_params,\n",
    "                          cv=10,\n",
    "                          n_jobs=-1,\n",
    "                          scoring='neg_mean_squared_error')\n",
    "    gs_rfr.fit(X_train, y_train)\n",
    "    \n",
    "    return gs_rfr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07edb56",
   "metadata": {},
   "source": [
    "### Visualization of results\n",
    "\n",
    "The R2 is an inadequate score for nonlinear models. Thus the root mean squared error (RMSE) were employed for comparing the predictive performance between the three algorithms.\n",
    "\n",
    "The scatter plot shows the result of the observed and predicted Fa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1835188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization_results(model, X_test, y_test):\n",
    "    #予測値\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(f'Correlation coefficient between observed and predicted values: {round(np.corrcoef(y_pred, y_test)[1,0], 4)}')\n",
    "    \n",
    "    #グラフのスケール設定\n",
    "    y_min = min([min(list(y_test)), min(list(y_pred))])\n",
    "    y_max = max([max(list(y_test)), max(list(y_pred))])\n",
    "    \n",
    "    ###実測値と予測値の散布図###\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    #散布図\n",
    "    plt.scatter(y_test, y_pred)\n",
    "    #タイトル\n",
    "    plt.title('Scatter plot, RMSE: {}'.format(round(np.sqrt(np.sum((y_pred - y_test)**2)/len(y_test)), 4)),fontsize=14)\n",
    "    plt.xlabel('Observed value')\n",
    "    plt.ylabel('Predicted value')\n",
    "    \n",
    "    #グラフ間の距離の調整\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf6233f",
   "metadata": {},
   "source": [
    "## Results: Fa Prediction using 1D2D Descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769ec9c1",
   "metadata": {},
   "source": [
    "### Checking Data Distribution \n",
    "\n",
    "The distributions of this dataset in terms of molecular weight and slogp that were calculated using Mordred are shown in Figure 1 in body text. The p-values of the Wilcoxon signed rank test were higher than 0.05 in the converted Fa, MW, and slogp measurements, confirming that there was no bias in the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd0caab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = distribution_conformation(df_2Ddescriptors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2422a2",
   "metadata": {},
   "source": [
    "### Model Construction\n",
    "\n",
    "The suitable parameters were selected using GridsearchCV (cv=10, score=’neg-mean-squared-error')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b4e2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = descriptor_preparation(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ca40f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfr_model = model_construction_rfr(X_train, y_train)\n",
    "rfr_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844d32c8",
   "metadata": {},
   "source": [
    "### Result Visualization\n",
    "\n",
    "The predicted Fa was calculated with RFR model constructed using 1D and 2D descriptor. The x-axis and y-axis show the values of converted Fa. The correlation coefficient scores between the observed and predicted values were 0.6861."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ee424c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualization_results(rfr_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b6944f",
   "metadata": {},
   "source": [
    "### Contribution of descriptors for Fa prediction\n",
    "\n",
    "Although the generated relationship between the descriptors and predicted results were effective for compound optimization, the constructed models were complex, and it was difficult to elucidate their relationships. Shapley additive explanations (SHAP) is a useful tool to overcome this hurdle, where the method calculates an important value of each feature for a prediction based on game theory. In Fa prediction by RFR, low values of TopoPSA(NO) and VSA_EState are likely to increase output value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36566481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "print('shap version: ', shap.__version__)\n",
    "\n",
    "# load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "\n",
    "# Create object that can calculate shap values\n",
    "explainer = shap.KernelExplainer(rfr_model.predict, pd.DataFrame(X_test).values)\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer.shap_values(X_test.values)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7145e8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
